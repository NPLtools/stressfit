{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shapes as S\n",
    "import sample as sam\n",
    "import graphs as gr\n",
    "import mccfit as mc\n",
    "from IPython.display import HTML\n",
    "deg = np.pi/180.\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<b>To hide/show the code blocks, click <a href=\"javascript:code_toggle()\">here</a>.</b>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter viewer\n",
    "Examples with output of the STRESSFIT scripts are available via Jupyter viewer server:\n",
    "<p>\n",
    "<a href='http://nbviewer.jupyter.org/url/neutron.ujf.cas.cz/restrax/download/stressfit/stressfit_example1.ipynb'>STRESSFIT</a>: Example session with data fitting (this script).\n",
    "</p>\n",
    "<p>\n",
    "For more information, see: <br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/saroun_MECASENS_2017.pdf'>MECASENS 2017 poster</a><br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/ECRS2018_stressfit.pdf'>ECRS10, 2018, slides</a><br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/saroun_ECNS2019_poster.pdf'>ECNS 2019, poster</a> <br/>\n",
    "</p>\n",
    "<p>\n",
    "For access to the complete python code, contact the author.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRESSFIT\n",
    "<p>\n",
    "<i>Written by:</i> Jan Saroun, Nuclear Physics Institute CAS, Rez, saroun@ujf.cas.cz<br/>\n",
    "<i>Date:</i> 22/05/2018\n",
    "</p>\n",
    "<p>\n",
    "This script permits to treat pseudo strains in neutron residual strain measurements. Pseudo strains due to partial immersion of sampling volume in the sample, steep intrinsic strain gradients and heterogeneous distribution of scattering probability can be treated. The script employs Monte Carlo convolution method, which uses sampling points produced by Monte Carlo ray-tracing simulation of the diffractometer to model smearing of intrinsic sample properties by instrumental response. Each point has all available information about a scattering event: position, initial and final neutron wave vector, probability and dhkl value associated with this sampling point. Such a sampling distribution can be simulated rather quickly for any instrument setup, for example by the ray-tracing program SIMRES (http://neutron.ujf.cas.cz/restrax). The sampling distribution is then reused to cary out the convolution with any sample shape, position, orientation and strain distribution. This decoupling of MC ray-tracing simulation from the convolution procedure permits to write a code which is rather fast (typically about 1s per one scan at 1 CPU). It is therefore possible to use the MC integration as a part of cost function for least squares fitting.\n",
    "</p><p>\n",
    "Development of a Python library STRESSFIT aims at providing tools for analysis of residual stress measurements, where pseudo strains can't be avoided and must be taken into account in data processing. Currently, STRESSFIT enables to model pseudo strains for several basic sample shapes (curved plates, full and hollow cylinders and spheres). It also enables least squares fitting of measured scans for a single strain component. Simultaneous fitting of multiple components with a single stress distribution model is envisaged in future versions. \n",
    "</p>\n",
    "\n",
    "## Jupyter viewer\n",
    "Examples with output of STRESSFIT are also available via Jupyter viewer server:\n",
    "<p>\n",
    "<a href='http://nbviewer.jupyter.org/url/neutron.ujf.cas.cz/restrax/download/stressfit/stressfit_example1.ipynb'>\n",
    "Example 1</a>: ECNS2019, Fitting of strain gradient under the inner surface of a tube, test on synthetic data for STRESS-SPEC.\n",
    "</p>\n",
    "\n",
    "## Documentation\n",
    "<p>\n",
    "For more information, see: <br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/saroun_MECASENS_2017.pdf'>MECASENS 2017 poster</a><br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/ECRS2018_stressfit.pdf'>ECRS10, 2018, slides</a><br/>\n",
    "<a href='http://neutron.ujf.cas.cz/restrax/download/stressfit/saroun_ECNS2019_poster.pdf'>ECNS 2019, poster</a> <br/>\n",
    "</p>\n",
    "<p>\n",
    "For access to the complete python code, contact the author.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define environment\n",
    "# input data folder\n",
    "inpath = mc.path2win(r'.\\input')\n",
    "# output data folder\n",
    "outpath = mc.path2win(r'.\\output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample definition\n",
    "Following block defines the <b>sample shape, position and orientation.</b>\n",
    "### Coordinates\n",
    "The laboratory frame is defined by y-axis vertical and z-axis pointing along the incident beam.\n",
    "The positioning includes rotation by YXY Euler angles ($\\omega$, $\\chi$, $\\phi$) and a linear shift (multiple commands <code>rotate</code> and <code>moveTo</code> are possible to achieve required position).\n",
    "\n",
    "Imported MC events are defined in the laboratory frame, with the origin at the centre of the instrumental gauge volume. Sample position and orientation thus define zero scan position and scan direction in the sample.\n",
    "\n",
    "### Sample shape\n",
    "Sample dimensions depend on the selected shape. Choose one of the classes defined in the Shapes folder of the package:\n",
    "\n",
    "<code> S.ShapePlate(thickness) </code> <br />\n",
    "An infinitely large flat plate of given thickness.\n",
    "\n",
    "<code> S.ShapePlateCurved(thickness, length, height, [r1x, r1y],  [r2x, r2y]) </code><br />\n",
    "A curved plate of given thickness (z), length (x) and height (y). <code>[r1x, r1y]</code> are curvature radii along x and y of the front surcae (z>0). <code>[r2x, r2y]</code> are the radii for the rear surface.\n",
    "\n",
    "<code> S.ShapeCyl(radius, height) </code><br />\n",
    "A cylindrical shape with axis along y-axis.\n",
    "\n",
    "<code> S.ShapeShellCyl(Rin, Rout, height) </code><br /> \n",
    "A hollow cylinder with axis along y-axis. Rin, Rout are the inner and outer radii.\n",
    "\n",
    "<code> S.ShapeSph(radius) </code> <br />\n",
    "A spherical sample.\n",
    "\n",
    "The next block in this template defines a tube: a hollow cylinder with inner radius 4 mm, outer radius 8 mm and height 50 mm. Zero scan position corresponds to the instrumental gauge volume centered at the surface. Measured strain direction is defined by the angle <code>omega</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Sample orientation:\n",
    "\n",
    "# Sample rotation. \n",
    "# At zero angles, the z-axis is parallel to the beam, y-axis is vertical.\n",
    "# omega, chi, phi are Euler angles (rotation around Y, X, Y).\n",
    "# Example for a plate symmetric reflection with incidence angle = theta:\n",
    "#   set chi=0, phi=0, omega=90 + theta\n",
    "\n",
    "omega = 180*deg + 45*deg\n",
    "chi = 0.0*deg\n",
    "phi = 0.0*deg\n",
    "\n",
    "# Scattering angle\n",
    "take_off = 91.77*deg \n",
    "\n",
    "# Set sample shape (see comment above).\n",
    "# Dimensions [mm]\n",
    "radius1 = 4.\n",
    "radius2 = 8\n",
    "height = 50.0\n",
    "shape = S.ShapeShellCyl(radius1, radius2, height)\n",
    "\n",
    "# Set sample position\n",
    "shape.rotate(omega, chi, phi)\n",
    "shape.moveTo(np.array([0., 0., 0]))\n",
    "\n",
    "# Assign shape\n",
    "sam.shape = shape\n",
    "\n",
    "# Define beam attenuation coefficient. Uncomment one of the two options: \n",
    "# Option 1: Set attenuation as a table (wavelength, mu), [1/cm]. The file must be in the input directory.\n",
    "exttab = np.loadtxt('Fe_mu.dat')\n",
    "sam.setExtinction(table=exttab)  # lookup table\n",
    "\n",
    "# Option 2: Set attenuation as a single coefficient [1/cm]:\n",
    "# sam.setExtinction(mu=1.96) # single value\n",
    "\n",
    "# define ki and kf vectors in laboratory frame\n",
    "ki = np.array([0., 0., 1.])  # default for SIMRES simulations\n",
    "kf = sam.rotate(ki, 1, take_off) # rotation of ki by the take-off angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling distribution\n",
    "Load Monte Carlo events representing the sampling distribution from a text file.\n",
    "The event table contains neutron coordinates, weights and dhkl values.  You need to specify column numbers for position, ki and kf vectors, weights and dhkl.\n",
    "\n",
    "Imported MC events are defined in the laboratory frame, with the origin at the centre of the instrumental gauge volume. Sample and orientation thus defines zero scan position and scan direction in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sampling points\n",
    "gpath = r'./input/'\n",
    "data = np.loadtxt(gpath + \"events_S_1mm.dat\")\n",
    "columns = [1, 4, 7, 10, 11]  # index of r[0], ki[0], kf[0], weight and dhkl (column indexing starts from 0)\n",
    "nrec = data.shape[0]\n",
    "\n",
    "# Set the events to the sample component\n",
    "sam.setSamplingEvents(data, columns)\n",
    "\n",
    "# Calculate centre of mass of the distribution \n",
    "P = data[:,columns[3]]/np.sum(data[:,columns[3]])\n",
    "ctr = np.zeros(3)\n",
    "for i in range(3):\n",
    "\tctr[i] = data[:, columns[0] + i].dot(P)\n",
    "dmean = data[:, columns[4]].dot(P)\n",
    "print('Loaded event list with {:d} records'.format(nrec))    \n",
    "print('Gauge centre: [{:g}, {:g}, {:g}] '.format(*ctr))\n",
    "print('d0 = {:g}\\n'.format(dmean))\n",
    "\n",
    "# Set the events to the sample component\n",
    "sam.setSamplingEvents(data, columns, ctr=ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan definition\n",
    "Define scan steps, direction and calculate corresponding depth scale. At the end, the diffraction geometry is plotted together with the sampling points. <b>The red arrow shows the direction of sample motion.</b>  Color scale of the sampling points shows the associated pseudo-strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan direction (local coordinates)\n",
    "sdir = [0., 0., -1.]\n",
    "# number of sampling events to use for convolution\n",
    "nev = 2000    \n",
    "\n",
    "# plot the situation\n",
    "nd = nev  # number of events to show\n",
    "rang = [13, 13]  # plot range in [mm]\n",
    "proj = 1  # projection plane (zy=0, xz=1, xy=2)\n",
    "outpng = outpath + 'scene.png'\n",
    "gr.plotScene(rang, proj, shape, ki, kf, sdir, sam.getSampling(nev) , save = True, file = outpng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "Load integral peak intensities and strains measured as a function of scan depth in two separate arrays with three columns: depth [mm], intensity [any unit] or strain [$\\mu\\epsilon = 10^{-6}$] and error (std. deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intensities, file name\n",
    "intfile = 'int_SS_hoop.dat'\n",
    "\n",
    "# intensities, file name\n",
    "epsfile = 'eps_SS_hoop.dat'\n",
    "\n",
    "# load data\n",
    "intdata = np.loadtxt(inpath + intfile)\n",
    "epsdata = np.loadtxt(inpath + epsfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit intensities\n",
    "Fitting of intensities allows to determine the variation of scattering probability and extinction with scan depth. It can also help to correct for any missfit between the encoder positions (stored in the data file) and true surface position. Note that sometimes these effects can't be distinguished from each other. With a strong variation of scattering probability (e.g. due to a greadient in texture or composition near the surface), it is not possible to reliably determine the surface position and extinction just from the intensity variation. Then some of the parameters must be determined independently and fixed for fitting. On the other hand, it is the product of extinction and scattering probability distributions which affects pseudo-strains, therefore they do not need to be exactly distinguished.\n",
    "\n",
    "NOTE:<br/>\n",
    "Scattering probability and strain distributions are defined on depth scale, where depth is the shortest distance to the front sample surface. Definition of the <i>front surface</i> depends on the sample shape. For plates, it is the distance to the upper surface (in local coordinates of the sample). For sphers and cylinders, it is the distance from the curved surface (the outer one in the case of hollow shapes).\n",
    "\n",
    "### Define initial values\n",
    "\n",
    "The depth distributions are modelled as a set of points interpolated by splines of selected order (1 to 3). Define below a minimum number of depth and intensity values which gives a satisfactory estimate of the intensity variation. Obviously, the intensity values should be kept constant for homogeneous materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMETERS\n",
    "# Give initial values, followed by flags (0|1), fx=1 means a free variable, 0 for fixed. \n",
    "\n",
    "# depth values [mm]\n",
    "x =  [0., 1., 2.5, 3.5, 4]\n",
    "fx = [0, 0, 0, 0, 0]\n",
    "\n",
    "# intrinsic scattering intensity [rel. units]\n",
    "y = [1., 1.0, 1.0, 1., 1.]\n",
    "fy = [0, 0, 0, 0, 0]\n",
    "\n",
    "# Set the method for interpolation between the nodes.\n",
    "# Use one of 'natural','clamped', 'PCHIP', 'Akima'\n",
    "interpolation = 'PCHIP' # PCHIP = Piecewise cubic Hermitian interpolation polynomial\n",
    "\n",
    "# Background and amplitude\n",
    "A = 33000\n",
    "B = 0\n",
    "# fixed (0) or free (1):\n",
    "fA = 1\n",
    "fB = 0\n",
    "\n",
    "# zero encoder position = position of the front surface in encoder scale\n",
    "# = where is the surcae position in the data table ...\n",
    "zc = 0.05\n",
    "# fixed (0) or free (1):\n",
    "fzc = 1\n",
    "\n",
    "#--------------------------------------------\n",
    "# Initialize model\n",
    "# nev = number of neutrons to use\n",
    "# xdir = the scan direction (defined above)\n",
    "ifit = mc.Ifit(nev=2000, xdir = sdir, ftol=1.e-3, epsfcn=0.1)\n",
    "\n",
    "# assign exp. data to the model\n",
    "ifit.data = intdata\n",
    "\n",
    "# define the intensity distribution, dim=number of points for interpolation \n",
    "ifit.defDistribution([x, y], [fx, fy], ndim=200)\n",
    "# define scaling (background, amplitude and depth shift). minval,maxval=limits of these parameters.\n",
    "ifit.defScaling([A, B, zc], [fA, fB, fzc], minval=[0., 0., -np.inf])\n",
    "# set the interpolation method\n",
    "ifit.setInterpModel(interpolation)\n",
    "\n",
    "# Guess fit (optional)\n",
    "# It makes a fast first estimate.  \n",
    "# Set maxiter=0 if you don't want to fit, just plot the initial model.\n",
    "mc.runFit(ifit, maxiter=0, guess=True)\n",
    "\n",
    "# show plots\n",
    "# Add file=name parameter if you want to save the result.\n",
    "ifit.reportFit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run fit\n",
    "Is the above estimate good? Then execute the following box to run fitting procedure and plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bootstrap method for estimation of confidence limits?\n",
    "bootstrap = False\n",
    "# Set loops for the number of bootstrap cycles.\n",
    "loops = 3\n",
    "# regularization\n",
    "areg = 1e-3\n",
    "# Set True to run intensity fit\n",
    "runIFit = True\n",
    "\n",
    "if runIFit:\n",
    "    res = mc.runFit(ifit, maxiter=100, areg=areg, bootstrap=bootstrap, loops=loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifit.reportFit(outpath=outpath, file=intfile, plotSampling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fit strain distribution\n",
    "Fitting of strain depth distribution is similar to the above procedure for fitting intensities. The scattering probability distribution determined above will be automatically taken into account in modelling of pseudo-strains below.\n",
    "\n",
    "### Define initial values\n",
    "\n",
    "The depth distributions are modelled as a set of points [depth, $\\epsilon$(depth)] interpolated by splines of selected order (1 to 3). Define below a minimum number of depth and strain values which gives a satisfactory estimate of the strain distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strain depth distribution  \n",
    "# Give initial values, followed by flags (0|1), fx=1 means a free variable, 0 for fixed.  \n",
    "\n",
    "# initial depth values [mm]\n",
    "x =  [0., 1., 2.0 , 2.5, 3.0 ,  3.5  , 3.7  ,   4.]\n",
    "fx = len(x)*[1]\n",
    "fx[-1] = 0\n",
    "\n",
    "# initial strain values [1e-6]\n",
    "y =  len(x)*[0.]\n",
    "fy = len(y)*[1]\n",
    "fy[0]=0\n",
    "\n",
    "\n",
    "# Set the method for interpolation between the nodes.\n",
    "# Use one of 'natural','clamped', 'PCHIP', 'Akima'\n",
    "# PCHIP = Piecewise cubic Hermitian interpolation polynomial\n",
    "interpolation = 'natural' \n",
    "\n",
    "# Calculate d0 correction from the bulk strain values?\n",
    "d0auto = False\n",
    "if d0auto:\n",
    "    # Define data range to be used for calculation of eps0:\n",
    "    n = epsdata.shape[0]  # total number of rows in the input data\n",
    "    # n1, n2: point index in 0 .. n-1 range\n",
    "    n1 = int(0.5*n) - 2  # 1st range point \n",
    "    n2 = int(0.5*n) + 2  # last range point \n",
    "    # python range convention: epsdata.shape[0]-1 is the last row index.\n",
    "else:\n",
    "    # give value of eps0 in strain units:\n",
    "    eps0  = 0.    \n",
    "\n",
    "# Define a constraint function (optional)\n",
    "def constraint(params):\n",
    "    # constraint example: keeps surface strain at 0 with 50ue tolerance\n",
    "    dist = mc.params2dist(params)\n",
    "    y=dist[1,1]\n",
    "    return (y-0.)/50. \n",
    "# set True to actually apply the above constraint\n",
    "use_constraint=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make fit estimate\n",
    "\n",
    "Run the code below. There is rarely a need to edit anything there, but you can still change some details such as number of sampling events, tolerance, number of iterations, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use surface position from intensity fit\n",
    "zc = ifit.params['xc'].value\n",
    "print('Using surface position: {:g}\\n'.format(zc))\n",
    "\n",
    "#--------------------------------------------\n",
    "# Calculate dependences\n",
    " \n",
    "if d0auto:\n",
    "    # calculate pseudo-strain\n",
    "    y0 = np.zeros(len(y))\n",
    "    sfit = mc.Sfit(nev=2000, xdir=sdir, ftol=1.e-3)\n",
    "    sfit.defDistribution([x, y0*y], [y0*fx, y0*fy], ndim=100)\n",
    "    tmp = sfit.getSmearedFnc(epsdata[:,0])\n",
    "    eps1 = np.average(tmp[0][n1:n2+1])\n",
    "    # get the average measured strain from selected range\n",
    "    eps2 = np.average(epsdata[n1:n2+1,1])\n",
    "    # subtract pseudo-strain\n",
    "    eps0 = eps2 - eps1\n",
    "    \"\"\" NOTE: we must subtract pseudo-strain since it is taken into account \n",
    "    by the convolution procedure. eps0 includes only an intrinsic d0 shift\n",
    "    or an instrumental effect other than the pseudo-strain (e.g. misalignment)\n",
    "    \"\"\"\n",
    "    fmt = 'd0 calculated form points {:d} to {:d}:\\neps0 = {:g}'\n",
    "    print(fmt.format(n1, n2, eps0))\n",
    "    # exclude n1 .. n2 range from fitting\n",
    "    tofit = np.concatenate((epsdata[0:n1,:],epsdata[n2:,:]), axis=0)\n",
    "else:\n",
    "    tofit = epsdata\n",
    "    \n",
    "# Initialize model\n",
    "sfit = mc.Sfit(nev=3000, xdir=sdir, ftol=1.e-3)\n",
    "\n",
    "# data to be fitted\n",
    "sfit.data = tofit\n",
    "\n",
    "# choose randomly a subset of sampling events\n",
    "sam.shuffleEvents()\n",
    "\n",
    "# define strain distribution, dim=number of points for interpolation \n",
    "# par = nodes [x,y] values\n",
    "# vary = corresponding flags for fixed (0) or free(1) variables.\n",
    "sfit.defDistribution(par=[x, y], vary=[fx, fy], ndim=100, scaled=True)\n",
    "\n",
    "# define function scaling (amplitude, strain offset, depth-shift) \n",
    "sfit.defScaling(par=[1., eps0, zc], vary=[0, 0, 0])\n",
    "\n",
    "# define interpolation method\n",
    "sfit.setInterpModel(interpolation)\n",
    "\n",
    "# define depth range to calculate integrated strain\n",
    "sfit.avgrange = [0., max(x)]\n",
    "\n",
    "\n",
    "# set use_constraint=false if you don't want to use the above defined constraint function:\n",
    "if (use_constraint):\n",
    "    sfit.constraint = constraint\n",
    "\n",
    "# Guess fit - the same as for intensity fitting\n",
    "mc.runFit(sfit, maxiter=300, areg=1e-7, bootstrap=False, loops=False, guess=True)\n",
    "sfit.reportFit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fit\n",
    "\n",
    "Is the above estimate good? Then you can edit the fit parameters below and execute the following box.\n",
    "It can run a bootstrap cycle to estimate confidence limit. \n",
    "\n",
    "It can also scan through the defined range of regularization coefficients (areg) to optimize the smoothing term.\n",
    "\n",
    "Set runReg=False below if you want to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use bootstrap method for estimation of confidence limits?\n",
    "bootstrap = True\n",
    "# Set loops for the number of bootstrap cycles.\n",
    "loops = 5\n",
    "# Run regularization loop?\n",
    "runReg = False\n",
    "# Define a list of regularization factors:\n",
    "areg = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "# Set to True to run strain fit\n",
    "runSFit = True\n",
    "# maximum iterations\n",
    "maxit=300\n",
    "\n",
    "#------------------------------\n",
    "# keep following as is\n",
    "reglog = None\n",
    "if runSFit and runReg:\n",
    "    na = len(areg)\n",
    "    reglog = np.zeros((na,3))\n",
    "    for ia in range(na):    \n",
    "        res = mc.runFit(sfit, maxiter=maxit, areg=areg[ia], bootstrap=False, loops=loops)\n",
    "        reglog[ia] = [areg[ia], sfit.chi, sfit.reg]\n",
    "        ss = '[areg, chi2, reg] = {:g}\\t{:g}\\t{:g}\\n'.format(*reglog[ia,:])\n",
    "        print(ss)\n",
    "        sfx = 'a{:g}_'.format(areg[ia])\n",
    "        sfit.reportFit(outpath=outpath, file=sfx+epsfile, reglog=reglog) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report the table with regularization progress:\n",
    "if runSFit and runReg:\n",
    "    ss = 'areg\\tchi2\\treg\\n'\n",
    "    for ia in range(na):\n",
    "        ss += '{:g}\\t{:g}\\t{:g}\\n'.format(*reglog[ia,:])\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best areg value and run fit \n",
    "if runSFit:\n",
    "    areg = 1e-7\n",
    "    maxit=300\n",
    "    res = mc.runFit(sfit, maxiter=maxit, areg=areg, bootstrap=bootstrap, loops=loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfit.reportFit(outpath=outpath, file=epsfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
